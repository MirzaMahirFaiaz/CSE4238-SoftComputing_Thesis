{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pdc3PspECrdE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMMhsAEx8h-Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def merge_stock_and_news_data(company_name):\n",
        "    company_data_path = f'drive/MyDrive/SoftComp/Dhaka Stock Exchange Historical Data/Adjusted Data/{company_name}.csv'\n",
        "    news_data_path = 'drive/MyDrive/SoftComp/prothomalo_data.csv'\n",
        "\n",
        "    # Read data from CSV files\n",
        "    stock_df = pd.read_csv(company_data_path)\n",
        "    news_df = pd.read_csv(news_data_path)\n",
        "\n",
        "    # Columns to select from each DataFrame\n",
        "    cols_from_stock = ['Date', 'Close']\n",
        "    cols_from_news = ['Date', 'headline']\n",
        "\n",
        "    # Convert 'Date' column to datetime format\n",
        "    stock_df['Date'] = pd.to_datetime(stock_df['Date']).dt.strftime('%d-%m-%Y')\n",
        "    news_df.rename(columns={'published_at': 'Date'}, inplace=True)\n",
        "\n",
        "    # Merge DataFrames on 'Date' column\n",
        "    merged_df = pd.merge(news_df[cols_from_news], stock_df[cols_from_stock], on='Date', how='inner')\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Example usage:\n",
        "company_name = \"BEXIMCO\"\n",
        "\n",
        "merged_df = merge_stock_and_news_data(company_name)\n",
        "print(merged_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4duCEXq9EAT",
        "outputId": "3e488539-f192-4eb4-afee-c7b154c21714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date                                      headline  Close\n",
            "0  06-07-2022             জিপি ও রবির দাপটে লেনদেন বাড়ল ৪৫%  132.9\n",
            "1  30-06-2022  ৬ মাসে বন্ধ কোম্পানির শেয়ারের দাম বেড়ে ৫ গুণ  129.8\n",
            "2  26-06-2022                      ডিএসইতে লেনদেন কমেছে ১১%  132.2\n",
            "3  16-06-2022       ‘কালোটাকা বিনিয়োগের সুযোগ বিবেচনাযোগ্য’  134.6\n",
            "4  15-06-2022                   টানা দরপতন চলছে শেয়ারবাজারে  131.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "Pdc3PspECrdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input, concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called 'merged_df'\n",
        "# Extract features and target\n",
        "X_text = merged_df['headline'].values\n",
        "X_date = pd.to_datetime(merged_df['Date']).values\n",
        "X_numerical = merged_df[['Volume', 'Open', 'High', 'Low']].values\n",
        "y = merged_df['Close'].values\n",
        "\n",
        "# Text data preprocessing\n",
        "max_words = 1000  # Set the maximum number of words in your vocabulary\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_text)\n",
        "X_text_sequence = tokenizer.texts_to_sequences(X_text)\n",
        "X_text_padded = pad_sequences(X_text_sequence, padding='post')\n",
        "\n",
        "# Convert datetime to numeric format (e.g., Unix timestamp)\n",
        "X_date_numeric = X_date.astype(np.int64) // 10**9  # Convert to seconds for simplicity\n",
        "\n",
        "# Normalize numerical data\n",
        "scaler = MinMaxScaler()\n",
        "X_numerical = scaler.fit_transform(X_numerical)\n",
        "\n",
        "# Define the input shapes for each type of data\n",
        "text_input_shape = X_text_padded.shape[1]\n",
        "date_input_shape = 1  # Scalar input for date\n",
        "numerical_input_shape = X_numerical.shape[1]\n",
        "\n",
        "# Define input layers\n",
        "text_input = Input(shape=(text_input_shape,))\n",
        "date_input = Input(shape=(date_input_shape,))\n",
        "numerical_input = Input(shape=(numerical_input_shape,))\n",
        "\n",
        "# Embedding layer for text input\n",
        "embedded_text = Embedding(input_dim=max_words, output_dim=50, input_length=text_input_shape)(text_input)\n",
        "lstm_out = LSTM(50)(embedded_text)\n",
        "\n",
        "# Concatenate the outputs from different input branches\n",
        "concatenated = concatenate([lstm_out, date_input, numerical_input])\n",
        "\n",
        "# Dense layer\n",
        "output = Dense(1)(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[text_input, date_input, numerical_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train-test split\n",
        "X_train_text, X_test_text, X_train_date, X_test_date, X_train_numerical, X_test_numerical, y_train, y_test = train_test_split(\n",
        "    X_text_padded, X_date_numeric, X_numerical, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    [X_train_text, X_train_date, X_train_numerical], y_train, epochs=100, batch_size=32,\n",
        "    validation_data=([X_test_text, X_test_date, X_test_numerical], y_test)\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate([X_test_text, X_test_date, X_test_numerical], y_test)\n",
        "print(f'Mean Squared Error on Test Data: {loss}')\n"
      ],
      "metadata": {
        "id": "PQwd1HoDFkLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b2484f-9ab5-48f0-fa08-f901fa3f8313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-861a6962154d>:13: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "  X_date = pd.to_datetime(merged_df['Date']).values\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Volume', 'Open', 'High', 'Low'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-861a6962154d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6130\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Volume', 'Open', 'High', 'Low'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble (Early Fusion)"
      ],
      "metadata": {
        "id": "TfeOOjUEPcDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Embedding, Flatten, Input, LSTM, MaxPooling1D, Reshape, ZeroPadding1D, concatenate, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import AutoModel, AutoTokenizer\n"
      ],
      "metadata": {
        "id": "TWMZHpQSPds1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "# df = pd.read_csv(\"your_dataset.csv\")\n",
        "\n",
        "# Convert date to datetime format\n",
        "# df[\"Date\"] = pd.to_datetime(df[\"Date\"], format='%d-%m-%Y')\n",
        "\n",
        "# Sort by date\n",
        "# df = df.sort_values(\"Date\")\n",
        "\n",
        "df = merged_df\n",
        "# df_test = merged_df.iloc[15:30]\n",
        "# Split into X (headlines and prices) and y (closing price)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DPEkdsTESqdF",
        "outputId": "97e36b22-fd3b-4786-a76b-44081d146f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date                                      headline  Close\n",
              "0  06-07-2022             জিপি ও রবির দাপটে লেনদেন বাড়ল ৪৫%  132.9\n",
              "1  30-06-2022  ৬ মাসে বন্ধ কোম্পানির শেয়ারের দাম বেড়ে ৫ গুণ  129.8\n",
              "2  26-06-2022                      ডিএসইতে লেনদেন কমেছে ১১%  132.2\n",
              "3  16-06-2022       ‘কালোটাকা বিনিয়োগের সুযোগ বিবেচনাযোগ্য’  134.6\n",
              "4  15-06-2022                   টানা দরপতন চলছে শেয়ারবাজারে  131.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eaf835a0-263b-4603-b78a-c3c49a543c81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>headline</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>06-07-2022</td>\n",
              "      <td>জিপি ও রবির দাপটে লেনদেন বাড়ল ৪৫%</td>\n",
              "      <td>132.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30-06-2022</td>\n",
              "      <td>৬ মাসে বন্ধ কোম্পানির শেয়ারের দাম বেড়ে ৫ গুণ</td>\n",
              "      <td>129.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26-06-2022</td>\n",
              "      <td>ডিএসইতে লেনদেন কমেছে ১১%</td>\n",
              "      <td>132.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16-06-2022</td>\n",
              "      <td>‘কালোটাকা বিনিয়োগের সুযোগ বিবেচনাযোগ্য’</td>\n",
              "      <td>134.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15-06-2022</td>\n",
              "      <td>টানা দরপতন চলছে শেয়ারবাজারে</td>\n",
              "      <td>131.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eaf835a0-263b-4603-b78a-c3c49a543c81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eaf835a0-263b-4603-b78a-c3c49a543c81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eaf835a0-263b-4603-b78a-c3c49a543c81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-671cebf6-6f96-47ec-992c-088283748c52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-671cebf6-6f96-47ec-992c-088283748c52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-671cebf6-6f96-47ec-992c-088283748c52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "bangla_model = TFBertModel.from_pretrained(\"sagorsarker/bangla-bert-base\", from_pt=True)\n",
        "\n",
        "# Define a function to encode Bengali text\n",
        "def encode_bengali_text(text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"tf\")\n",
        "    embeddings = bangla_model(input_ids)[0]\n",
        "    return embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "FmffJIsADL8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ce08c5-84aa-4294-8d4a-08636645d12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 128  # You can adjust this based on your headlines\n",
        "headline_texts = df['headline'].tolist()\n",
        "headline_input = tokenizer(headline_texts, padding='max_length', truncation=True, max_length=max_sequence_length, return_tensors='tf')\n",
        "\n",
        "\n",
        "# Preprocess numerical data\n",
        "numerical_data = df['Close'].values.reshape(-1, 1)  # Assuming 'Close' is the numerical column\n",
        "scaler = StandardScaler()\n",
        "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "# Reshape X_text to have the same dimensions as X_price\n",
        "# X_text = np.expand_dims(X_text, axis=1)\n",
        "# print(X_text[0].shape, X_text[1].shape)\n",
        "# print(X_price)\n",
        "# Split data into training and testing sets (now compatible dimensions)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     np.concatenate([X_text, X_price], axis=1), y, test_size=0.2, random_state=42\n",
        "# )\n",
        "headline_train, headline_test, numerical_train, numerical_test, labels_train, labels_test = train_test_split(\n",
        "    headline_input['input_ids'].numpy(), numerical_data_scaled, df['Close'].values, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "QFHTaBT842rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(np.array(X_headline_encoded)))\n",
        "# X_headline_encoded[0].numpy().shape\n",
        "for i, t in enumerate(headline_input['input_ids']):\n",
        "  print(f\"{df['headline'].iloc[i]}\\n{t.shape}\")"
      ],
      "metadata": {
        "id": "_s0mW_pSkH0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Early Fusion model architecture with pre-encoded text tensors\n",
        "text_input = Input(shape=(128,), name=\"text_input\")  # Adjust shape based on embedding dimension\n",
        "conv_layer = Reshape((128, 1))(text_input)  # Reshape to include channel dimension for Conv1D\n",
        "conv_layer = Conv1D(filters=32, kernel_size=3, activation=\"relu\")(conv_layer)\n",
        "pool_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "\n",
        "# Price processing branch\n",
        "price_input = Input(shape=(1, ), name=\"price_input\")  # Shape for single timestep\n",
        "# Reshape the input tensor to include the timestep dimension\n",
        "reshaped_price_input = Reshape((1, 1))(price_input)\n",
        "lstm_layer = LSTM(32)(reshaped_price_input)\n",
        "\n",
        "# Repeat the numerical input to match the sequence length of the text input\n",
        "repeated_numerical_input = RepeatVector(64)(lstm_layer)  # Assuming sequence length after pooling is 64\n",
        "padded_pool_layer = ZeroPadding1D(padding=(0, 1))(pool_layer)\n",
        "# Fusion layer\n",
        "merged = concatenate([padded_pool_layer, repeated_numerical_input])\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation=\"linear\")(merged)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[text_input, price_input], outputs=output_layer)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM2BnRrB5WnE",
        "outputId": "f986736a-871f-4303-d602-8768e3a6ea8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_input (InputLayer)     [(None, 128)]                0         []                            \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)        (None, 128, 1)               0         ['text_input[0][0]']          \n",
            "                                                                                                  \n",
            " price_input (InputLayer)    [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)          (None, 126, 32)              128       ['reshape_11[0][0]']          \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)        (None, 1, 1)                 0         ['price_input[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling1d_27 (MaxPooli  (None, 63, 32)               0         ['conv1d_32[0][0]']           \n",
            " ng1D)                                                                                            \n",
            "                                                                                                  \n",
            " lstm_27 (LSTM)              (None, 32)                   4352      ['reshape_12[0][0]']          \n",
            "                                                                                                  \n",
            " zero_padding1d_3 (ZeroPadd  (None, 64, 32)               0         ['max_pooling1d_27[0][0]']    \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " repeat_vector_11 (RepeatVe  (None, 64, 32)               0         ['lstm_27[0][0]']             \n",
            " ctor)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 64, 64)               0         ['zero_padding1d_3[0][0]',    \n",
            " e)                                                                  'repeat_vector_11[0][0]']    \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 64, 1)                65        ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4545 (17.75 KB)\n",
            "Trainable params: 4545 (17.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the model with pre-encoded text tensors\n",
        "# model.fit(\n",
        "#     [X_headline_encoded, X_price], y_train, epochs=10, validation_data=([X_test_headline_encoded, X_test_price], y_test)\n",
        "# )\n",
        "print(labels_train)\n",
        "# Train the model\n",
        "model.fit([headline_train, numerical_train], labels_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate([headline_test, numerical_test], labels_test)\n",
        "print(\"Test Loss: \", loss)"
      ],
      "metadata": {
        "id": "U1YvCH6MEaIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Together"
      ],
      "metadata": {
        "id": "xijW4KuS1_LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_for(company_name):\n",
        "  print(\"Running for: \" + company_name)\n",
        "  def merge_stock_and_news_data(company_name):\n",
        "      company_data_path = f'drive/MyDrive/SoftComp/Dhaka Stock Exchange Historical Data/Adjusted Data/{company_name}.csv'\n",
        "      news_data_path = 'drive/MyDrive/SoftComp/prothomalo_data.csv'\n",
        "\n",
        "      # Read data from CSV files\n",
        "      stock_df = pd.read_csv(company_data_path)\n",
        "      news_df = pd.read_csv(news_data_path)\n",
        "\n",
        "      # Columns to select from each DataFrame\n",
        "      cols_from_stock = ['Date', 'Close']\n",
        "      cols_from_news = ['Date', 'headline']\n",
        "\n",
        "      # Convert 'Date' column to datetime format\n",
        "      stock_df['Date'] = pd.to_datetime(stock_df['Date']).dt.strftime('%d-%m-%Y')\n",
        "      news_df.rename(columns={'published_at': 'Date'}, inplace=True)\n",
        "\n",
        "      # Merge DataFrames on 'Date' column\n",
        "      merged_df = pd.merge(news_df[cols_from_news], stock_df[cols_from_stock], on='Date', how='inner')\n",
        "\n",
        "      return merged_df\n",
        "\n",
        "  # Example usage:\n",
        "  # company_name = \"ABBANK\"\n",
        "\n",
        "  df = merge_stock_and_news_data(company_name)\n",
        "  # print(df.head())\n",
        "\n",
        "  #====\n",
        "\n",
        "  import tensorflow as tf\n",
        "  from transformers import TFAutoModel, AutoTokenizer\n",
        "  from transformers import TFBertModel, BertTokenizer\n",
        "\n",
        "  # Load the tokenizer and model\n",
        "  tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "  bangla_model = TFBertModel.from_pretrained(\"sagorsarker/bangla-bert-base\", from_pt=True)\n",
        "\n",
        "  # Define a function to encode Bengali text\n",
        "  def encode_bengali_text(text):\n",
        "      input_ids = tokenizer.encode(text, return_tensors=\"tf\")\n",
        "      embeddings = bangla_model(input_ids)[0]\n",
        "      return embeddings\n",
        "\n",
        "  #==========\n",
        "\n",
        "  max_sequence_length = 128  # You can adjust this based on your headlines\n",
        "  headline_texts = df['headline'].tolist()\n",
        "  headline_input = tokenizer(headline_texts, padding='max_length', truncation=True, max_length=max_sequence_length, return_tensors='tf')\n",
        "\n",
        "\n",
        "  # Preprocess numerical data\n",
        "  numerical_data = df['Close'].values.reshape(-1, 1)  # Assuming 'Close' is the numerical column\n",
        "  scaler = StandardScaler()\n",
        "  numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "\n",
        "  headline_train, headline_test, numerical_train, numerical_test, labels_train, labels_test = train_test_split(\n",
        "      headline_input['input_ids'].numpy(), numerical_data_scaled, df['Close'].values, test_size=0.2, random_state=42\n",
        "  )\n",
        "\n",
        "  #==========\n",
        "\n",
        "  # Define Early Fusion model architecture with pre-encoded text tensors\n",
        "  text_input = Input(shape=(128,), name=\"text_input\")  # Adjust shape based on embedding dimension\n",
        "  conv_layer = Reshape((128, 1))(text_input)  # Reshape to include channel dimension for Conv1D\n",
        "  conv_layer = Conv1D(filters=32, kernel_size=3, activation=\"relu\")(conv_layer)\n",
        "  pool_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "\n",
        "  # Price processing branch\n",
        "  price_input = Input(shape=(1, ), name=\"price_input\")  # Shape for single timestep\n",
        "  # Reshape the input tensor to include the timestep dimension\n",
        "  reshaped_price_input = Reshape((1, 1))(price_input)\n",
        "  lstm_layer = LSTM(32)(reshaped_price_input)\n",
        "\n",
        "  # Repeat the numerical input to match the sequence length of the text input\n",
        "  repeated_numerical_input = RepeatVector(64)(lstm_layer)  # Assuming sequence length after pooling is 64\n",
        "  padded_pool_layer = ZeroPadding1D(padding=(0, 1))(pool_layer)\n",
        "  # Fusion layer\n",
        "  merged = concatenate([padded_pool_layer, repeated_numerical_input])\n",
        "\n",
        "  # Output layer\n",
        "  output_layer = Dense(1, activation=\"linear\")(merged)\n",
        "\n",
        "  # Create the model\n",
        "  model = Model(inputs=[text_input, price_input], outputs=output_layer)\n",
        "  model.compile(optimizer=\"adam\", loss=\"mae\")\n",
        "\n",
        "  # Print model summary\n",
        "  # model.summary()\n",
        "\n",
        "  #========\n",
        "\n",
        "  # Train the model\n",
        "  model.fit([headline_train, numerical_train], labels_train, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "  # Evaluate the model\n",
        "  loss = model.evaluate([headline_test, numerical_test], labels_test)\n",
        "  print(\"Test Loss: \", loss)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "I5WbXaQX1WwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Directory path\n",
        "directory = 'drive/MyDrive/SoftComp/Dhaka Stock Exchange Historical Data/Adjusted Data/'\n",
        "\n",
        "# Get all files in the directory\n",
        "files = os.listdir(directory)\n",
        "\n",
        "# Filter CSV files and remove extension\n",
        "csv_files = [file.split('.')[0] for file in files if file.endswith('.csv')]\n",
        "\n",
        "losses = {}\n",
        "\n",
        "# Simulating the process for the first 5 companies\n",
        "for company in csv_files[:25]:\n",
        "    loss = run_for(company)\n",
        "    losses[company] = loss\n",
        "\n",
        "# Save all losses to a single CSV file\n",
        "output_file = os.path.join(directory, 'all_losses.csv')\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Company', 'Loss'])\n",
        "    for company, loss in losses.items():\n",
        "        writer.writerow([company, loss])"
      ],
      "metadata": {
        "id": "ExOfnAEi2yA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_for(\"DACCADYE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiwdxPg8MMDo",
        "outputId": "27643752-d399-4da3-da73-209a09a88889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for: DACCADYE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "46/46 [==============================] - 4s 29ms/step - loss: 115.3068 - val_loss: 77.8491\n",
            "Epoch 2/20\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 52.5552 - val_loss: 34.3366\n",
            "Epoch 3/20\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 29.0709 - val_loss: 24.5080\n",
            "Epoch 4/20\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 22.3818 - val_loss: 19.3363\n",
            "Epoch 5/20\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 17.4533 - val_loss: 15.9837\n",
            "Epoch 6/20\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 14.9522 - val_loss: 15.3328\n",
            "Epoch 7/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 13.0775 - val_loss: 12.3362\n",
            "Epoch 8/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 11.2982 - val_loss: 10.3471\n",
            "Epoch 9/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 10.1044 - val_loss: 9.7984\n",
            "Epoch 10/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 9.8605 - val_loss: 8.6078\n",
            "Epoch 11/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 8.3936 - val_loss: 7.8805\n",
            "Epoch 12/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.9063 - val_loss: 7.3613\n",
            "Epoch 13/20\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 7.3023 - val_loss: 7.1309\n",
            "Epoch 14/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.4269 - val_loss: 9.3429\n",
            "Epoch 15/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.5338 - val_loss: 7.5155\n",
            "Epoch 16/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 7.1130 - val_loss: 6.7604\n",
            "Epoch 17/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 7.2895 - val_loss: 7.1206\n",
            "Epoch 18/20\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 6.9128 - val_loss: 6.8703\n",
            "Epoch 19/20\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 7.0364 - val_loss: 6.6891\n",
            "Epoch 20/20\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 6.5807 - val_loss: 7.9286\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.6907\n",
            "Test Loss:  7.690665245056152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.690665245056152"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Company|Loss|\n",
        "|---|---|\n",
        "|COPPERTECH|3676\\.3701171875|\n",
        "|DACCADYE|697\\.7158813476562|\n",
        "|EMERALDOIL|1668\\.7244873046875|\n",
        "|EASTLAND|955\\.0673217773438|\n",
        "|DESCO|3441\\.3203125|\n",
        "|DBH|4648\\.8525390625|\n",
        "|ECABLES|16513\\.33984375|\n",
        "|CVOPRL|61835\\.171875|\n",
        "|CROWNCEMNT|22674\\.333984375|\n",
        "|CITYBANK|1034\\.007080078125|\n",
        "|DOMINAGE|1762\\.115478515625|\n",
        "|ENVOYTEX|1276\\.8028564453125|\n",
        "|FAMILYTEX|1653\\.0316162109375|\n",
        "|DELTASPINN|2299\\.0712890625|\n",
        "|BXSYNTH|1368\\.7296142578125|\n",
        "|CITYGENINS|1913\\.43017578125|\n",
        "|CONFIDCEM|5183\\.931640625|\n",
        "|FARCHEM|1099\\.353515625|\n",
        "|DHAKABANK|1139\\.431884765625|\n",
        "|BPPL|54990\\.4921875|\n",
        "|DHAKAINS|1439\\.9873046875|\n",
        "|DSHGARME|16711\\.75390625|\n",
        "|EBL|981\\.372802734375|\n",
        "|CENTRALINS|1460\\.9859619140625|\n",
        "|BSRMSTEEL|2805\\.183837890625|"
      ],
      "metadata": {
        "id": "c26bYDEAMM08"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oW_Tq_ce3hFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}